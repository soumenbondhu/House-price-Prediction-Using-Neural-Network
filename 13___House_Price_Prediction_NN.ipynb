{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-F11rRKT61ru"
   },
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Paj4DrdC5OxY"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eci_EtfE7cWm"
   },
   "outputs": [],
   "source": [
    "# unzipping the downloaded file\n",
    "# https://www.kaggle.com/harlfoxem/housesalesprediction\n",
    "\n",
    "!unzip /content/archive_house.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvBNRSIc7fGe"
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv('/content/kc_house_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "drYnfiSCxcjn",
    "outputId": "c0a3c880-7eb2-46c2-c2f8-34a112f24770"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7237550310</td>\n",
       "      <td>20140512T000000</td>\n",
       "      <td>1225000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5420</td>\n",
       "      <td>101930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3890</td>\n",
       "      <td>1530</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98053</td>\n",
       "      <td>47.6561</td>\n",
       "      <td>-122.005</td>\n",
       "      <td>4760</td>\n",
       "      <td>101930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1321400060</td>\n",
       "      <td>20140627T000000</td>\n",
       "      <td>257500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3097</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008000270</td>\n",
       "      <td>20150115T000000</td>\n",
       "      <td>291850.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1060</td>\n",
       "      <td>9711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.4095</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>1650</td>\n",
       "      <td>9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2414600126</td>\n",
       "      <td>20150415T000000</td>\n",
       "      <td>229500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1780</td>\n",
       "      <td>7470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>730</td>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5123</td>\n",
       "      <td>-122.337</td>\n",
       "      <td>1780</td>\n",
       "      <td>8113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3793500160</td>\n",
       "      <td>20150312T000000</td>\n",
       "      <td>323000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1890</td>\n",
       "      <td>6560</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1890</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>98038</td>\n",
       "      <td>47.3684</td>\n",
       "      <td>-122.031</td>\n",
       "      <td>2390</td>\n",
       "      <td>7570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date      price  ...     long  sqft_living15  sqft_lot15\n",
       "0  7129300520  20141013T000000   221900.0  ... -122.257           1340        5650\n",
       "1  6414100192  20141209T000000   538000.0  ... -122.319           1690        7639\n",
       "2  5631500400  20150225T000000   180000.0  ... -122.233           2720        8062\n",
       "3  2487200875  20141209T000000   604000.0  ... -122.393           1360        5000\n",
       "4  1954400510  20150218T000000   510000.0  ... -122.045           1800        7503\n",
       "5  7237550310  20140512T000000  1225000.0  ... -122.005           4760      101930\n",
       "6  1321400060  20140627T000000   257500.0  ... -122.327           2238        6819\n",
       "7  2008000270  20150115T000000   291850.0  ... -122.315           1650        9711\n",
       "8  2414600126  20150415T000000   229500.0  ... -122.337           1780        8113\n",
       "9  3793500160  20150312T000000   323000.0  ... -122.031           2390        7570\n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FywWMhw1-EJH"
   },
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kH87-Drv76iS",
    "outputId": "197beb5b-8b16-4bb5-ce03-c74c94b25fd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking how many data points and how my features do we have.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNQE-We88Asd"
   },
   "source": [
    "This means there are 21 features. Out of these 21 features, 1 is target feature. Rest 20 are my input features.\n",
    "\n",
    "\n",
    "There are 21613 data points in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8xXWj1T8QEp",
    "outputId": "69b8ce93-77e7-429c-b7b4-bd4cd9213c48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
       "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
       "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
       "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking what features we have\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGp00ytT7yWF",
    "outputId": "8eb1a4ea-ce72-4311-d939-5593cc06e59c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21613 non-null  int64  \n",
      " 1   date           21613 non-null  object \n",
      " 2   price          21613 non-null  float64\n",
      " 3   bedrooms       21613 non-null  int64  \n",
      " 4   bathrooms      21613 non-null  float64\n",
      " 5   sqft_living    21613 non-null  int64  \n",
      " 6   sqft_lot       21613 non-null  int64  \n",
      " 7   floors         21613 non-null  float64\n",
      " 8   waterfront     21613 non-null  int64  \n",
      " 9   view           21613 non-null  int64  \n",
      " 10  condition      21613 non-null  int64  \n",
      " 11  grade          21613 non-null  int64  \n",
      " 12  sqft_above     21613 non-null  int64  \n",
      " 13  sqft_basement  21613 non-null  int64  \n",
      " 14  yr_built       21613 non-null  int64  \n",
      " 15  yr_renovated   21613 non-null  int64  \n",
      " 16  zipcode        21613 non-null  int64  \n",
      " 17  lat            21613 non-null  float64\n",
      " 18  long           21613 non-null  float64\n",
      " 19  sqft_living15  21613 non-null  int64  \n",
      " 20  sqft_lot15     21613 non-null  int64  \n",
      "dtypes: float64(5), int64(15), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# getting the information about the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7Oca5788ocf"
   },
   "source": [
    "From here we get to see that no columns have missing values. which is a good sign. This means no missing value imputation is needed.\n",
    "\n",
    "Along with that, one feature is of object type. that needs to be converted into something which the machine can understands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMsjCaiW-G9e"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QVo4tKJU0flg",
    "outputId": "43e973c1-99ac-4fc3-df93-c7b657138399"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   id             21613 non-null  int64         \n",
      " 1   date           21613 non-null  datetime64[ns]\n",
      " 2   price          21613 non-null  float64       \n",
      " 3   bedrooms       21613 non-null  int64         \n",
      " 4   bathrooms      21613 non-null  float64       \n",
      " 5   sqft_living    21613 non-null  int64         \n",
      " 6   sqft_lot       21613 non-null  int64         \n",
      " 7   floors         21613 non-null  float64       \n",
      " 8   waterfront     21613 non-null  int64         \n",
      " 9   view           21613 non-null  int64         \n",
      " 10  condition      21613 non-null  int64         \n",
      " 11  grade          21613 non-null  int64         \n",
      " 12  sqft_above     21613 non-null  int64         \n",
      " 13  sqft_basement  21613 non-null  int64         \n",
      " 14  yr_built       21613 non-null  int64         \n",
      " 15  yr_renovated   21613 non-null  int64         \n",
      " 16  zipcode        21613 non-null  int64         \n",
      " 17  lat            21613 non-null  float64       \n",
      " 18  long           21613 non-null  float64       \n",
      " 19  sqft_living15  21613 non-null  int64         \n",
      " 20  sqft_lot15     21613 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(5), int64(15)\n",
      "memory usage: 3.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "a9UNI8cx8oAY",
    "outputId": "96dc46ec-c41c-4c68-c3f4-eb44e16a052b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>2014-10-13</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id       date     price  ...     long  sqft_living15  sqft_lot15\n",
       "0  7129300520 2014-10-13  221900.0  ... -122.257           1340        5650\n",
       "1  6414100192 2014-12-09  538000.0  ... -122.319           1690        7639\n",
       "2  5631500400 2015-02-25  180000.0  ... -122.233           2720        8062\n",
       "3  2487200875 2014-12-09  604000.0  ... -122.393           1360        5000\n",
       "4  1954400510 2015-02-18  510000.0  ... -122.045           1800        7503\n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting month and year from the date column\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z77mY2mp1i0-"
   },
   "outputs": [],
   "source": [
    "a=df['date'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UAO9LVmy73rK"
   },
   "outputs": [],
   "source": [
    "def date2month(x):\n",
    "  return x.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bh6-We69mLZ"
   },
   "outputs": [],
   "source": [
    "def date2year(x):\n",
    "  return x.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icpHBk399n_u"
   },
   "outputs": [],
   "source": [
    "df['month']=df['date'].apply(date2month)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GRmAR0Uy3Ult",
    "outputId": "5eddc7a4-ae06-4ca5-e6ed-7234f045d664"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['month'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "qjF4RsZ_3hqf",
    "outputId": "74640e70-f5d8-47c9-a59a-c4bb7af3deae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>2014-10-13</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id       date     price  ...  sqft_lot15  month  year\n",
       "0  7129300520 2014-10-13  221900.0  ...        5650     10  2014\n",
       "1  6414100192 2014-12-09  538000.0  ...        7639     12  2014\n",
       "2  5631500400 2015-02-25  180000.0  ...        8062      2  2015\n",
       "3  2487200875 2014-12-09  604000.0  ...        5000     12  2014\n",
       "4  1954400510 2015-02-18  510000.0  ...        7503      2  2015\n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year']=df['date'].apply(date2year)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wmu7FH---2wt"
   },
   "outputs": [],
   "source": [
    "# now we will remove the date column.\n",
    "\n",
    "df=df.drop(columns='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "IfaAKbe69xWH",
    "outputId": "690d8fe7-5d18-4824-b47d-d2bd8fe64be1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id     price  bedrooms  ...  sqft_lot15  month  year\n",
       "0  7129300520  221900.0         3  ...        5650     10  2014\n",
       "1  6414100192  538000.0         3  ...        7639     12  2014\n",
       "2  5631500400  180000.0         2  ...        8062      2  2015\n",
       "3  2487200875  604000.0         4  ...        5000     12  2014\n",
       "4  1954400510  510000.0         3  ...        7503      2  2015\n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Tg4s49Z9ytc"
   },
   "outputs": [],
   "source": [
    "# id is not so important feature, so i will remove it.\n",
    "\n",
    "df=df.drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "iH-Zca3L97Fs",
    "outputId": "51e65bd9-f4a5-475e-bc57-c5b38c0abe73"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bedrooms  bathrooms  ...  sqft_lot15  month  year\n",
       "0  221900.0         3       1.00  ...        5650     10  2014\n",
       "1  538000.0         3       2.25  ...        7639     12  2014\n",
       "2  180000.0         2       1.00  ...        8062      2  2015\n",
       "3  604000.0         4       3.00  ...        5000     12  2014\n",
       "4  510000.0         3       2.00  ...        7503      2  2015\n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5N0axY1B98NR",
    "outputId": "b5e0eb25-0e14-4d50-d6a3-d446a2e6bd87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   price          21613 non-null  float64\n",
      " 1   bedrooms       21613 non-null  int64  \n",
      " 2   bathrooms      21613 non-null  float64\n",
      " 3   sqft_living    21613 non-null  int64  \n",
      " 4   sqft_lot       21613 non-null  int64  \n",
      " 5   floors         21613 non-null  float64\n",
      " 6   waterfront     21613 non-null  int64  \n",
      " 7   view           21613 non-null  int64  \n",
      " 8   condition      21613 non-null  int64  \n",
      " 9   grade          21613 non-null  int64  \n",
      " 10  sqft_above     21613 non-null  int64  \n",
      " 11  sqft_basement  21613 non-null  int64  \n",
      " 12  yr_built       21613 non-null  int64  \n",
      " 13  yr_renovated   21613 non-null  int64  \n",
      " 14  zipcode        21613 non-null  int64  \n",
      " 15  lat            21613 non-null  float64\n",
      " 16  long           21613 non-null  float64\n",
      " 17  sqft_living15  21613 non-null  int64  \n",
      " 18  sqft_lot15     21613 non-null  int64  \n",
      " 19  month          21613 non-null  int64  \n",
      " 20  year           21613 non-null  int64  \n",
      "dtypes: float64(5), int64(16)\n",
      "memory usage: 3.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omfIclpv-O9x"
   },
   "source": [
    "Before sending the dataset to the machine, we need to mention which of these are input features and 54which of these are target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDxwG4M79_Z3"
   },
   "outputs": [],
   "source": [
    "# splitting the dataset\n",
    "\n",
    "X=df.drop(columns='price')\n",
    "y=df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "SNm1HrAl-wMH",
    "outputId": "2f6429fa-330a-41ae-8e0c-2740e0026e40"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  sqft_living  ...  sqft_lot15  month  year\n",
       "0         3       1.00         1180  ...        5650     10  2014\n",
       "1         3       2.25         2570  ...        7639     12  2014\n",
       "2         2       1.00          770  ...        8062      2  2015\n",
       "3         4       3.00         1960  ...        5000     12  2014\n",
       "4         3       2.00         1680  ...        7503      2  2015\n",
       "\n",
       "[5 rows x 20 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TU3AtDR1_CJq",
    "outputId": "759f9659-b604-40ac-f127-1be048fb68c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    221900.0\n",
       "1    538000.0\n",
       "2    180000.0\n",
       "3    604000.0\n",
       "4    510000.0\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYzWlkF5_XNi"
   },
   "source": [
    "Now this dataset will be divided into training and testing datasets.\n",
    "\n",
    "The training dataset will be used t train the model and the testing dataset will be used to evaluate and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tzPK5dth_W9h"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8-5B2pY_xyj",
    "outputId": "462dbbc2-86a2-43bc-8a4b-56fbe2ce6b95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15129, 20)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sNAXbgwF_0kC",
    "outputId": "db95c5de-e319-4d00-ffaf-746cc8aeef4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15129,)"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlkwPfi0_2I5",
    "outputId": "f3422849-e3b9-494a-ab87-11c00ef88cb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6484, 20)"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CzwfJhp8_4kt",
    "outputId": "ec76ba91-5d84-4267-d402-4c37cf445fb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6484,)"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xPh425l-qQU"
   },
   "source": [
    "Now we need to scale the features so that all of them are in the same range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "g113VZkJ9w8i",
    "outputId": "6bdc3eec-ecf6-47d2-ff0c-328ba4997bc2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9677</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2110</td>\n",
       "      <td>13939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1270</td>\n",
       "      <td>840</td>\n",
       "      <td>1978</td>\n",
       "      <td>0</td>\n",
       "      <td>98008</td>\n",
       "      <td>47.6431</td>\n",
       "      <td>-122.113</td>\n",
       "      <td>2140</td>\n",
       "      <td>8882</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19682</th>\n",
       "      <td>4</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3276</td>\n",
       "      <td>10801</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3276</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98166</td>\n",
       "      <td>47.4585</td>\n",
       "      <td>-122.361</td>\n",
       "      <td>2010</td>\n",
       "      <td>11656</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13437</th>\n",
       "      <td>4</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1960</td>\n",
       "      <td>4635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>960</td>\n",
       "      <td>1968</td>\n",
       "      <td>0</td>\n",
       "      <td>98118</td>\n",
       "      <td>47.5693</td>\n",
       "      <td>-122.285</td>\n",
       "      <td>1830</td>\n",
       "      <td>6180</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12095</th>\n",
       "      <td>4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2020</td>\n",
       "      <td>8474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1010</td>\n",
       "      <td>1010</td>\n",
       "      <td>1962</td>\n",
       "      <td>0</td>\n",
       "      <td>98058</td>\n",
       "      <td>47.4579</td>\n",
       "      <td>-122.170</td>\n",
       "      <td>1720</td>\n",
       "      <td>8166</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13892</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1000</td>\n",
       "      <td>6947</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1947</td>\n",
       "      <td>0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7142</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1000</td>\n",
       "      <td>6947</td>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14477</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>890</td>\n",
       "      <td>4810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>890</td>\n",
       "      <td>0</td>\n",
       "      <td>1910</td>\n",
       "      <td>0</td>\n",
       "      <td>98118</td>\n",
       "      <td>47.5153</td>\n",
       "      <td>-122.266</td>\n",
       "      <td>1230</td>\n",
       "      <td>6057</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17957</th>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2480</td>\n",
       "      <td>9238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2050</td>\n",
       "      <td>430</td>\n",
       "      <td>1913</td>\n",
       "      <td>0</td>\n",
       "      <td>98166</td>\n",
       "      <td>47.4701</td>\n",
       "      <td>-122.364</td>\n",
       "      <td>1820</td>\n",
       "      <td>12214</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17459</th>\n",
       "      <td>5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4510</td>\n",
       "      <td>15175</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4510</td>\n",
       "      <td>0</td>\n",
       "      <td>1969</td>\n",
       "      <td>2002</td>\n",
       "      <td>98040</td>\n",
       "      <td>47.5309</td>\n",
       "      <td>-122.228</td>\n",
       "      <td>3510</td>\n",
       "      <td>13500</td>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7730</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4040</td>\n",
       "      <td>11350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3690</td>\n",
       "      <td>350</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "      <td>98006</td>\n",
       "      <td>47.5590</td>\n",
       "      <td>-122.162</td>\n",
       "      <td>3770</td>\n",
       "      <td>12382</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14556</th>\n",
       "      <td>5</td>\n",
       "      <td>6.25</td>\n",
       "      <td>8670</td>\n",
       "      <td>64033</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>6120</td>\n",
       "      <td>2550</td>\n",
       "      <td>1965</td>\n",
       "      <td>2003</td>\n",
       "      <td>98177</td>\n",
       "      <td>47.7295</td>\n",
       "      <td>-122.372</td>\n",
       "      <td>4140</td>\n",
       "      <td>81021</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15129 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bedrooms  bathrooms  sqft_living  ...  sqft_lot15  month  year\n",
       "9677          4       2.50         2110  ...        8882      2  2015\n",
       "19682         4       3.25         3276  ...       11656      2  2015\n",
       "13437         4       2.75         1960  ...        6180      4  2015\n",
       "12095         4       1.50         2020  ...        8166      4  2015\n",
       "13892         3       1.00         1000  ...        6947      9  2014\n",
       "...         ...        ...          ...  ...         ...    ...   ...\n",
       "14477         3       1.00          890  ...        6057      3  2015\n",
       "17957         4       3.00         2480  ...       12214      7  2014\n",
       "17459         5       4.00         4510  ...       13500      5  2014\n",
       "7730          4       2.50         4040  ...       12382      3  2015\n",
       "14556         5       6.25         8670  ...       81021      6  2014\n",
       "\n",
       "[15129 rows x 20 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sZnVgjVI9_vC",
    "outputId": "2cce95d4-ff53-4145-8f2e-3db6143366b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66917192,  0.4909485 ,  0.02314765, ..., -0.14611507,\n",
       "        -1.46824962,  1.44461796],\n",
       "       [ 0.66917192,  1.45816265,  1.2836598 , ..., -0.04554305,\n",
       "        -1.46824962,  1.44461796],\n",
       "       [ 0.66917192,  0.81335321, -0.13901086, ..., -0.24407672,\n",
       "        -0.82536854,  1.44461796],\n",
       "       ...,\n",
       "       [ 1.73709407,  2.42537679,  2.61768381, ...,  0.0213116 ,\n",
       "        -0.503928  , -0.69222454],\n",
       "       [ 0.66917192,  0.4909485 ,  2.10958714, ..., -0.01922175,\n",
       "        -1.14680908,  1.44461796],\n",
       "       [ 1.73709407,  5.32701923,  7.11487982, ...,  2.46930126,\n",
       "        -0.18248746, -0.69222454]])"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1aNFwAZ-klR"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # To standardize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9V-mJr1dAaW_"
   },
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWyAOZvCAOhw"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UqH4u6FQAf7H"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(2,activation='relu'))\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vewKRJmDAhWp"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FrHn__PMA4f2",
    "outputId": "3d94d4c0-6bba-4b57-ec9e-bfe995d28d31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "473/473 [==============================] - 2s 2ms/step - loss: 444446058556.4894 - val_loss: 398787608576.0000\n",
      "Epoch 2/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 402039506486.0084 - val_loss: 221607133184.0000\n",
      "Epoch 3/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 174603409070.9873 - val_loss: 75246215168.0000\n",
      "Epoch 4/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 77290288408.8439 - val_loss: 64949518336.0000\n",
      "Epoch 5/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 66330481555.9831 - val_loss: 58671677440.0000\n",
      "Epoch 6/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 62743692378.7342 - val_loss: 53863256064.0000\n",
      "Epoch 7/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 57934108084.3882 - val_loss: 50271903744.0000\n",
      "Epoch 8/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 55954355109.2658 - val_loss: 46434250752.0000\n",
      "Epoch 9/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 49524564590.1772 - val_loss: 43112427520.0000\n",
      "Epoch 10/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 46221699750.3460 - val_loss: 40867737600.0000\n",
      "Epoch 11/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 42917471340.0169 - val_loss: 38718361600.0000\n",
      "Epoch 12/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 41233688900.0506 - val_loss: 37626048512.0000\n",
      "Epoch 13/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 38278185759.3249 - val_loss: 36058931200.0000\n",
      "Epoch 14/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 40419637675.7468 - val_loss: 34789281792.0000\n",
      "Epoch 15/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 36346920687.7975 - val_loss: 34378297344.0000\n",
      "Epoch 16/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 37102959032.7089 - val_loss: 33916006400.0000\n",
      "Epoch 17/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 34870569996.9620 - val_loss: 33246658560.0000\n",
      "Epoch 18/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 36280181193.9916 - val_loss: 32627208192.0000\n",
      "Epoch 19/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 34451501691.1392 - val_loss: 32833302528.0000\n",
      "Epoch 20/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 34906776014.3122 - val_loss: 32535818240.0000\n",
      "Epoch 21/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33326863843.9156 - val_loss: 32586641408.0000\n",
      "Epoch 22/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32059605622.8186 - val_loss: 32177866752.0000\n",
      "Epoch 23/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33566230156.4219 - val_loss: 32050546688.0000\n",
      "Epoch 24/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33198428713.0464 - val_loss: 31900170240.0000\n",
      "Epoch 25/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33452366394.3291 - val_loss: 31775793152.0000\n",
      "Epoch 26/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32713570584.8439 - val_loss: 32004444160.0000\n",
      "Epoch 27/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33756956101.6709 - val_loss: 31456221184.0000\n",
      "Epoch 28/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33482966577.6878 - val_loss: 31281858560.0000\n",
      "Epoch 29/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31616478864.7426 - val_loss: 31259109376.0000\n",
      "Epoch 30/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33271750111.5949 - val_loss: 31340843008.0000\n",
      "Epoch 31/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30458040687.2574 - val_loss: 32001677312.0000\n",
      "Epoch 32/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33598424534.9536 - val_loss: 31125309440.0000\n",
      "Epoch 33/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30936389186.9705 - val_loss: 30919905280.0000\n",
      "Epoch 34/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32906601022.6498 - val_loss: 30548035584.0000\n",
      "Epoch 35/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31833374370.0253 - val_loss: 30734608384.0000\n",
      "Epoch 36/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32187854757.2658 - val_loss: 30834767872.0000\n",
      "Epoch 37/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29683829766.4810 - val_loss: 31513622528.0000\n",
      "Epoch 38/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32591297605.1308 - val_loss: 31467812864.0000\n",
      "Epoch 39/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29895390169.1139 - val_loss: 30912077824.0000\n",
      "Epoch 40/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32060089521.1477 - val_loss: 30721910784.0000\n",
      "Epoch 41/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32567718108.3544 - val_loss: 29979539456.0000\n",
      "Epoch 42/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 34450049767.1561 - val_loss: 30342354944.0000\n",
      "Epoch 43/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30279846786.7004 - val_loss: 30304937984.0000\n",
      "Epoch 44/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28481495783.1561 - val_loss: 31165181952.0000\n",
      "Epoch 45/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32819746107.4093 - val_loss: 29940594688.0000\n",
      "Epoch 46/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32676955615.5949 - val_loss: 30163488768.0000\n",
      "Epoch 47/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31467695263.8650 - val_loss: 30997024768.0000\n",
      "Epoch 48/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31722121527.0886 - val_loss: 30105901056.0000\n",
      "Epoch 49/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32400806445.3671 - val_loss: 29912748032.0000\n",
      "Epoch 50/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33905281132.0169 - val_loss: 29787219968.0000\n",
      "Epoch 51/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29197562705.0127 - val_loss: 30614743040.0000\n",
      "Epoch 52/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31972135663.7975 - val_loss: 29922174976.0000\n",
      "Epoch 53/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29801044270.4473 - val_loss: 30699548672.0000\n",
      "Epoch 54/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29860623053.2321 - val_loss: 29932161024.0000\n",
      "Epoch 55/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29446039320.8439 - val_loss: 30006390784.0000\n",
      "Epoch 56/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31291086809.1139 - val_loss: 29828378624.0000\n",
      "Epoch 57/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30353123323.6793 - val_loss: 30176913408.0000\n",
      "Epoch 58/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31728286473.7215 - val_loss: 29694466048.0000\n",
      "Epoch 59/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30420372281.2489 - val_loss: 29828423680.0000\n",
      "Epoch 60/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28884533299.8481 - val_loss: 30131730432.0000\n",
      "Epoch 61/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28631518750.2447 - val_loss: 29935255552.0000\n",
      "Epoch 62/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30440603773.2996 - val_loss: 29652803584.0000\n",
      "Epoch 63/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30374601365.0633 - val_loss: 29319602176.0000\n",
      "Epoch 64/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31552390493.9747 - val_loss: 29435142144.0000\n",
      "Epoch 65/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29409544533.3333 - val_loss: 29563834368.0000\n",
      "Epoch 66/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31362178659.3755 - val_loss: 29368201216.0000\n",
      "Epoch 67/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31201922946.7004 - val_loss: 29208102912.0000\n",
      "Epoch 68/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29334601212.7595 - val_loss: 30414399488.0000\n",
      "Epoch 69/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29078921639.4262 - val_loss: 29920788480.0000\n",
      "Epoch 70/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29334483257.2489 - val_loss: 29313349632.0000\n",
      "Epoch 71/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28889252479.4599 - val_loss: 29929383936.0000\n",
      "Epoch 72/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31740913080.7089 - val_loss: 29820379136.0000\n",
      "Epoch 73/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30159929858.1603 - val_loss: 29402777600.0000\n",
      "Epoch 74/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29073228778.3966 - val_loss: 29459638272.0000\n",
      "Epoch 75/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28560284607.1899 - val_loss: 29914169344.0000\n",
      "Epoch 76/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28936182243.9156 - val_loss: 29054914560.0000\n",
      "Epoch 77/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27691647935.1899 - val_loss: 29437749248.0000\n",
      "Epoch 78/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32519473234.0928 - val_loss: 29346777088.0000\n",
      "Epoch 79/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31665118121.5865 - val_loss: 29492811776.0000\n",
      "Epoch 80/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29252306931.0380 - val_loss: 28974399488.0000\n",
      "Epoch 81/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27463704044.5570 - val_loss: 29443530752.0000\n",
      "Epoch 82/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28158814270.6498 - val_loss: 29579708416.0000\n",
      "Epoch 83/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28445312496.8776 - val_loss: 28984102912.0000\n",
      "Epoch 84/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28626734911.7300 - val_loss: 28881606656.0000\n",
      "Epoch 85/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28506950846.1097 - val_loss: 28699774976.0000\n",
      "Epoch 86/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27747747006.1097 - val_loss: 29136771072.0000\n",
      "Epoch 87/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26876174776.7089 - val_loss: 29163700224.0000\n",
      "Epoch 88/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29711621063.8312 - val_loss: 28627167232.0000\n",
      "Epoch 89/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27568217070.7173 - val_loss: 29485346816.0000\n",
      "Epoch 90/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28427961957.5359 - val_loss: 29236054016.0000\n",
      "Epoch 91/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27434824894.1097 - val_loss: 28520798208.0000\n",
      "Epoch 92/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29571086292.7932 - val_loss: 28468152320.0000\n",
      "Epoch 93/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30452519955.4430 - val_loss: 28250820608.0000\n",
      "Epoch 94/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27520687289.7890 - val_loss: 29053298688.0000\n",
      "Epoch 95/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31033344773.4008 - val_loss: 28550207488.0000\n",
      "Epoch 96/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29355698776.5738 - val_loss: 28592072704.0000\n",
      "Epoch 97/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29830261302.0084 - val_loss: 28196861952.0000\n",
      "Epoch 98/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28911898619.6793 - val_loss: 28099829760.0000\n",
      "Epoch 99/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29127890382.3122 - val_loss: 28308342784.0000\n",
      "Epoch 100/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27082796325.8059 - val_loss: 29113874432.0000\n",
      "Epoch 101/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27987155004.4895 - val_loss: 28332015616.0000\n",
      "Epoch 102/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27332465977.2489 - val_loss: 28048785408.0000\n",
      "Epoch 103/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30045789464.8439 - val_loss: 28597774336.0000\n",
      "Epoch 104/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27730116610.1603 - val_loss: 28255217664.0000\n",
      "Epoch 105/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27515857490.0928 - val_loss: 27816060928.0000\n",
      "Epoch 106/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27946266204.8945 - val_loss: 28033961984.0000\n",
      "Epoch 107/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29694209875.1730 - val_loss: 28231759872.0000\n",
      "Epoch 108/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27894728794.7342 - val_loss: 28319004672.0000\n",
      "Epoch 109/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27135279121.2827 - val_loss: 27983845376.0000\n",
      "Epoch 110/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26597300055.4937 - val_loss: 28680003584.0000\n",
      "Epoch 111/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25793548221.0295 - val_loss: 28320845824.0000\n",
      "Epoch 112/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27859600396.9620 - val_loss: 27833104384.0000\n",
      "Epoch 113/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27749000559.2574 - val_loss: 27767650304.0000\n",
      "Epoch 114/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28639932899.9156 - val_loss: 27840161792.0000\n",
      "Epoch 115/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27379542085.1308 - val_loss: 28188002304.0000\n",
      "Epoch 116/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28002816133.9409 - val_loss: 28376238080.0000\n",
      "Epoch 117/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28470262835.8481 - val_loss: 27739498496.0000\n",
      "Epoch 118/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26490387259.4093 - val_loss: 27989594112.0000\n",
      "Epoch 119/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28288470629.5359 - val_loss: 27575296000.0000\n",
      "Epoch 120/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27715749814.5485 - val_loss: 28243109888.0000\n",
      "Epoch 121/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26913115412.5232 - val_loss: 27872286720.0000\n",
      "Epoch 122/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26468804497.8228 - val_loss: 28077928448.0000\n",
      "Epoch 123/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27478379096.5738 - val_loss: 28084289536.0000\n",
      "Epoch 124/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29621921910.8186 - val_loss: 27380955136.0000\n",
      "Epoch 125/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26777162106.0591 - val_loss: 27632695296.0000\n",
      "Epoch 126/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25768690471.9662 - val_loss: 28036329472.0000\n",
      "Epoch 127/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26934463077.5359 - val_loss: 27608494080.0000\n",
      "Epoch 128/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27273233805.5021 - val_loss: 27414353920.0000\n",
      "Epoch 129/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27452947391.1899 - val_loss: 27571515392.0000\n",
      "Epoch 130/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25657272268.1519 - val_loss: 27441491968.0000\n",
      "Epoch 131/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26453771199.1899 - val_loss: 27567826944.0000\n",
      "Epoch 132/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26769604305.5527 - val_loss: 27662014464.0000\n",
      "Epoch 133/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28950815739.6793 - val_loss: 27004104704.0000\n",
      "Epoch 134/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27918181496.9789 - val_loss: 27613767680.0000\n",
      "Epoch 135/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26437238248.2363 - val_loss: 27026397184.0000\n",
      "Epoch 136/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27088102888.2363 - val_loss: 27525156864.0000\n",
      "Epoch 137/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24818957867.2068 - val_loss: 27719671808.0000\n",
      "Epoch 138/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26858189482.6667 - val_loss: 27828766720.0000\n",
      "Epoch 139/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27340403474.3629 - val_loss: 27627941888.0000\n",
      "Epoch 140/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25012661057.8903 - val_loss: 27384823808.0000\n",
      "Epoch 141/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24619385994.2616 - val_loss: 27756826624.0000\n",
      "Epoch 142/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28241394147.9156 - val_loss: 27223891968.0000\n",
      "Epoch 143/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27736606153.9916 - val_loss: 27199129600.0000\n",
      "Epoch 144/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25611332357.4008 - val_loss: 26966722560.0000\n",
      "Epoch 145/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25858428370.6329 - val_loss: 27115298816.0000\n",
      "Epoch 146/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24649850568.9114 - val_loss: 27609294848.0000\n",
      "Epoch 147/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26914153960.2363 - val_loss: 26933139456.0000\n",
      "Epoch 148/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25495737296.4726 - val_loss: 27690326016.0000\n",
      "Epoch 149/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26069113216.5401 - val_loss: 27196041216.0000\n",
      "Epoch 150/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26699152669.1646 - val_loss: 27497089024.0000\n",
      "Epoch 151/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26848674010.1941 - val_loss: 26754805760.0000\n",
      "Epoch 152/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26280656900.3207 - val_loss: 27587299328.0000\n",
      "Epoch 153/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26490180247.2236 - val_loss: 27249555456.0000\n",
      "Epoch 154/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26274714116.3207 - val_loss: 26629515264.0000\n",
      "Epoch 155/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27316149870.1772 - val_loss: 26833805312.0000\n",
      "Epoch 156/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25233463464.5063 - val_loss: 27537238016.0000\n",
      "Epoch 157/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25185518008.7089 - val_loss: 27387387904.0000\n",
      "Epoch 158/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26773492718.7173 - val_loss: 27000156160.0000\n",
      "Epoch 159/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25994176518.4810 - val_loss: 27163187200.0000\n",
      "Epoch 160/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26543734935.2236 - val_loss: 27155521536.0000\n",
      "Epoch 161/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25599149159.6962 - val_loss: 27378706432.0000\n",
      "Epoch 162/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26411864526.3122 - val_loss: 27412445184.0000\n",
      "Epoch 163/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23646703659.2068 - val_loss: 26959392768.0000\n",
      "Epoch 164/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25821192511.7300 - val_loss: 27239768064.0000\n",
      "Epoch 165/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27200163042.8354 - val_loss: 26482503680.0000\n",
      "Epoch 166/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24994390143.4599 - val_loss: 26959747072.0000\n",
      "Epoch 167/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25494843150.0422 - val_loss: 26613723136.0000\n",
      "Epoch 168/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24499397640.6413 - val_loss: 27592683520.0000\n",
      "Epoch 169/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26769350768.3376 - val_loss: 26727516160.0000\n",
      "Epoch 170/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23603768138.5316 - val_loss: 27638347776.0000\n",
      "Epoch 171/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25920535910.6160 - val_loss: 27564443648.0000\n",
      "Epoch 172/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24360823159.8987 - val_loss: 26846083072.0000\n",
      "Epoch 173/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24868212450.8354 - val_loss: 26283028480.0000\n",
      "Epoch 174/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25148356694.4135 - val_loss: 26691106816.0000\n",
      "Epoch 175/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25016976176.6076 - val_loss: 26650595328.0000\n",
      "Epoch 176/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24567234808.4388 - val_loss: 26824163328.0000\n",
      "Epoch 177/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24807285038.4473 - val_loss: 26797307904.0000\n",
      "Epoch 178/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25422094485.0633 - val_loss: 26733086720.0000\n",
      "Epoch 179/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24405013672.5063 - val_loss: 26247313408.0000\n",
      "Epoch 180/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25740301454.5823 - val_loss: 26685583360.0000\n",
      "Epoch 181/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25992274267.8143 - val_loss: 26329856000.0000\n",
      "Epoch 182/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23660115298.2954 - val_loss: 26738923520.0000\n",
      "Epoch 183/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23875149757.0295 - val_loss: 28126265344.0000\n",
      "Epoch 184/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26003656755.8481 - val_loss: 26415284224.0000\n",
      "Epoch 185/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24081642720.6751 - val_loss: 27262074880.0000\n",
      "Epoch 186/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24537803585.8903 - val_loss: 27004016640.0000\n",
      "Epoch 187/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25039747529.9916 - val_loss: 26152892416.0000\n",
      "Epoch 188/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24470567179.8819 - val_loss: 26341890048.0000\n",
      "Epoch 189/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25600082045.2996 - val_loss: 25952131072.0000\n",
      "Epoch 190/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23884083368.5063 - val_loss: 27032180736.0000\n",
      "Epoch 191/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24697201374.5148 - val_loss: 26533249024.0000\n",
      "Epoch 192/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25748266433.3502 - val_loss: 26622208000.0000\n",
      "Epoch 193/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24534330007.2236 - val_loss: 26250496000.0000\n",
      "Epoch 194/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23818106076.3544 - val_loss: 26320121856.0000\n",
      "Epoch 195/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23456290345.0464 - val_loss: 26327928832.0000\n",
      "Epoch 196/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24958417284.8608 - val_loss: 26506448896.0000\n",
      "Epoch 197/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24725301483.4768 - val_loss: 26203715584.0000\n",
      "Epoch 198/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23543137204.3882 - val_loss: 26664370176.0000\n",
      "Epoch 199/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24993842685.8397 - val_loss: 26448033792.0000\n",
      "Epoch 200/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24457481367.2236 - val_loss: 27021289472.0000\n",
      "Epoch 201/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24873650134.9536 - val_loss: 26086998016.0000\n",
      "Epoch 202/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24471670848.8101 - val_loss: 26194249728.0000\n",
      "Epoch 203/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24483381632.5401 - val_loss: 26446188544.0000\n",
      "Epoch 204/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24220495344.8776 - val_loss: 25808060416.0000\n",
      "Epoch 205/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24438115989.0633 - val_loss: 25927608320.0000\n",
      "Epoch 206/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24169570893.7722 - val_loss: 26608222208.0000\n",
      "Epoch 207/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24076018770.0928 - val_loss: 26742816768.0000\n",
      "Epoch 208/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24022265659.4093 - val_loss: 26769676288.0000\n",
      "Epoch 209/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23288750622.2447 - val_loss: 26162952192.0000\n",
      "Epoch 210/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24826428791.8987 - val_loss: 26824998912.0000\n",
      "Epoch 211/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24412803411.1730 - val_loss: 26124009472.0000\n",
      "Epoch 212/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25097597761.8903 - val_loss: 26238261248.0000\n",
      "Epoch 213/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23456047616.0000 - val_loss: 26791266304.0000\n",
      "Epoch 214/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23392287495.5612 - val_loss: 26036312064.0000\n",
      "Epoch 215/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24079202029.6371 - val_loss: 26714673152.0000\n",
      "Epoch 216/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25455391601.4177 - val_loss: 26182871040.0000\n",
      "Epoch 217/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24065212288.5401 - val_loss: 26796052480.0000\n",
      "Epoch 218/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23207560243.8481 - val_loss: 25956182016.0000\n",
      "Epoch 219/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24823515758.1772 - val_loss: 26998310912.0000\n",
      "Epoch 220/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23598935454.7848 - val_loss: 25847379968.0000\n",
      "Epoch 221/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23345430610.0928 - val_loss: 25915697152.0000\n",
      "Epoch 222/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22208829191.5612 - val_loss: 26229350400.0000\n",
      "Epoch 223/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23632848152.8439 - val_loss: 26554947584.0000\n",
      "Epoch 224/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23253270355.1730 - val_loss: 26371561472.0000\n",
      "Epoch 225/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21907570335.8650 - val_loss: 26093031424.0000\n",
      "Epoch 226/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23256890234.0591 - val_loss: 26243667968.0000\n",
      "Epoch 227/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23838313809.0127 - val_loss: 26150797312.0000\n",
      "Epoch 228/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23085480728.8439 - val_loss: 25574340608.0000\n",
      "Epoch 229/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24543744566.0084 - val_loss: 25954459648.0000\n",
      "Epoch 230/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22986281232.2025 - val_loss: 25678788608.0000\n",
      "Epoch 231/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24175693599.3249 - val_loss: 25470418944.0000\n",
      "Epoch 232/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23128139030.6835 - val_loss: 25811566592.0000\n",
      "Epoch 233/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23609444619.8819 - val_loss: 25984290816.0000\n",
      "Epoch 234/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23513254484.2532 - val_loss: 25795221504.0000\n",
      "Epoch 235/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23055284716.5570 - val_loss: 25912653824.0000\n",
      "Epoch 236/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22737112431.2574 - val_loss: 25673052160.0000\n",
      "Epoch 237/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24792770786.8354 - val_loss: 25359855616.0000\n",
      "Epoch 238/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23367778014.5148 - val_loss: 25946306560.0000\n",
      "Epoch 239/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24227028503.7637 - val_loss: 25482821632.0000\n",
      "Epoch 240/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23724552693.1983 - val_loss: 25777713152.0000\n",
      "Epoch 241/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23380285098.6667 - val_loss: 26159925248.0000\n",
      "Epoch 242/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24484193707.7468 - val_loss: 25870094336.0000\n",
      "Epoch 243/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23082920822.8186 - val_loss: 26247282688.0000\n",
      "Epoch 244/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24941887060.2532 - val_loss: 25315444736.0000\n",
      "Epoch 245/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22941304978.9030 - val_loss: 25661489152.0000\n",
      "Epoch 246/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25890481877.8734 - val_loss: 25578633216.0000\n",
      "Epoch 247/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22173272655.9325 - val_loss: 25635317760.0000\n",
      "Epoch 248/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23767091766.0084 - val_loss: 25004148736.0000\n",
      "Epoch 249/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21803927258.1941 - val_loss: 25860544512.0000\n",
      "Epoch 250/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22710564254.7848 - val_loss: 25411784704.0000\n",
      "Epoch 251/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21927867370.3966 - val_loss: 25415770112.0000\n",
      "Epoch 252/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24229602548.1181 - val_loss: 25237778432.0000\n",
      "Epoch 253/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23723851233.7553 - val_loss: 26611968000.0000\n",
      "Epoch 254/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23056215683.7806 - val_loss: 25550127104.0000\n",
      "Epoch 255/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21970845896.9114 - val_loss: 25798113280.0000\n",
      "Epoch 256/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22917144705.6203 - val_loss: 25267941376.0000\n",
      "Epoch 257/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23686723622.8861 - val_loss: 25543215104.0000\n",
      "Epoch 258/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22816703745.0802 - val_loss: 25531281408.0000\n",
      "Epoch 259/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23098812524.0169 - val_loss: 25560756224.0000\n",
      "Epoch 260/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22701038345.7215 - val_loss: 25955407872.0000\n",
      "Epoch 261/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21683718731.6118 - val_loss: 25897250816.0000\n",
      "Epoch 262/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22081568942.9873 - val_loss: 25503815680.0000\n",
      "Epoch 263/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22538937031.8312 - val_loss: 25035868160.0000\n",
      "Epoch 264/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23997165421.0970 - val_loss: 25479268352.0000\n",
      "Epoch 265/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23339046296.3038 - val_loss: 25435860992.0000\n",
      "Epoch 266/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22600613339.2743 - val_loss: 25882648576.0000\n",
      "Epoch 267/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22196992367.2574 - val_loss: 25487804416.0000\n",
      "Epoch 268/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23165894651.6793 - val_loss: 25380743168.0000\n",
      "Epoch 269/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23487450010.4641 - val_loss: 25331441664.0000\n",
      "Epoch 270/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23012771324.7595 - val_loss: 25043648512.0000\n",
      "Epoch 271/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22030537848.9789 - val_loss: 25933694976.0000\n",
      "Epoch 272/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22289549549.6371 - val_loss: 25337722880.0000\n",
      "Epoch 273/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22180629616.3376 - val_loss: 25347958784.0000\n",
      "Epoch 274/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21759191467.7468 - val_loss: 27218190336.0000\n",
      "Epoch 275/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22799993235.9831 - val_loss: 25112799232.0000\n",
      "Epoch 276/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22886842368.0000 - val_loss: 25692878848.0000\n",
      "Epoch 277/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21993624999.4262 - val_loss: 25278955520.0000\n",
      "Epoch 278/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21930975018.1266 - val_loss: 25906468864.0000\n",
      "Epoch 279/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21783953775.2574 - val_loss: 24923420672.0000\n",
      "Epoch 280/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21891318507.4768 - val_loss: 25213800448.0000\n",
      "Epoch 281/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22048529729.8903 - val_loss: 26304393216.0000\n",
      "Epoch 282/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22407247522.0253 - val_loss: 25882050560.0000\n",
      "Epoch 283/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23192289932.4219 - val_loss: 25070792704.0000\n",
      "Epoch 284/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22214997782.6835 - val_loss: 25393733632.0000\n",
      "Epoch 285/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22460700957.1646 - val_loss: 25256773632.0000\n",
      "Epoch 286/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22835556498.9030 - val_loss: 25106507776.0000\n",
      "Epoch 287/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21453904103.1561 - val_loss: 25127626752.0000\n",
      "Epoch 288/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21419342189.0970 - val_loss: 25263755264.0000\n",
      "Epoch 289/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22681605755.1392 - val_loss: 25034119168.0000\n",
      "Epoch 290/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21510682657.4852 - val_loss: 25381906432.0000\n",
      "Epoch 291/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22475140456.7764 - val_loss: 24978262016.0000\n",
      "Epoch 292/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21061036874.5316 - val_loss: 26142380032.0000\n",
      "Epoch 293/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21690399661.9072 - val_loss: 25036027904.0000\n",
      "Epoch 294/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22471961142.0084 - val_loss: 25637847040.0000\n",
      "Epoch 295/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22182553202.4979 - val_loss: 25114531840.0000\n",
      "Epoch 296/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21913469468.0844 - val_loss: 25068253184.0000\n",
      "Epoch 297/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21421010412.5570 - val_loss: 24740651008.0000\n",
      "Epoch 298/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20712827065.7890 - val_loss: 24946046976.0000\n",
      "Epoch 299/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22229524475.6793 - val_loss: 24700360704.0000\n",
      "Epoch 300/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21773575509.3333 - val_loss: 24794615808.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa285bcb9d0>"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,\n",
    "          validation_data=(X_test,y_test),\n",
    "          batch_size=32,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "JP6wnzSBFUDv",
    "outputId": "4e996247-c8f8-44a1-e797-991b6bd12e60"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.334493e+11</td>\n",
       "      <td>3.987876e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.584085e+11</td>\n",
       "      <td>2.216071e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.313636e+11</td>\n",
       "      <td>7.524622e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.435423e+10</td>\n",
       "      <td>6.494952e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.615895e+10</td>\n",
       "      <td>5.867168e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2.199273e+10</td>\n",
       "      <td>2.506825e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2.195294e+10</td>\n",
       "      <td>2.474065e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2.193443e+10</td>\n",
       "      <td>2.494605e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2.189205e+10</td>\n",
       "      <td>2.470036e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2.185384e+10</td>\n",
       "      <td>2.479462e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss      val_loss\n",
       "0    4.334493e+11  3.987876e+11\n",
       "1    3.584085e+11  2.216071e+11\n",
       "2    1.313636e+11  7.524622e+10\n",
       "3    7.435423e+10  6.494952e+10\n",
       "4    6.615895e+10  5.867168e+10\n",
       "..            ...           ...\n",
       "295  2.199273e+10  2.506825e+10\n",
       "296  2.195294e+10  2.474065e+10\n",
       "297  2.193443e+10  2.494605e+10\n",
       "298  2.189205e+10  2.470036e+10\n",
       "299  2.185384e+10  2.479462e+10\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl_adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "id": "lIXfx0xEA7BJ",
    "outputId": "44afbcc0-9048-498a-cce3-af133508171f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa282304e10>"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfl_adam= pd.DataFrame(model.history.history)\n",
    "dfl_adam.plot(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zHNbA9qdCSI8",
    "outputId": "bf882ed4-2bd7-498a-d9d7-365f57c264bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "473/473 [==============================] - 2s 2ms/step - loss: 423110312350.7848 - val_loss: 406588260352.0000\n",
      "Epoch 2/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 434203044315.2743 - val_loss: 393465921536.0000\n",
      "Epoch 3/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 423030032133.4008 - val_loss: 321149042688.0000\n",
      "Epoch 4/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 305079185805.5021 - val_loss: 151741661184.0000\n",
      "Epoch 5/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 132776327124.7932 - val_loss: 77221773312.0000\n",
      "Epoch 6/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 75181697378.2954 - val_loss: 63640420352.0000\n",
      "Epoch 7/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 65701510200.1688 - val_loss: 56280231936.0000\n",
      "Epoch 8/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 60846220456.5063 - val_loss: 50782924800.0000\n",
      "Epoch 9/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 50903752345.3840 - val_loss: 45830365184.0000\n",
      "Epoch 10/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 48245887001.9240 - val_loss: 42146553856.0000\n",
      "Epoch 11/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 45332073147.9494 - val_loss: 39417356288.0000\n",
      "Epoch 12/300\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 42097037540.9958 - val_loss: 37133443072.0000\n",
      "Epoch 13/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 42787390453.1983 - val_loss: 35397505024.0000\n",
      "Epoch 14/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 39090995843.7806 - val_loss: 34520973312.0000\n",
      "Epoch 15/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 36887738281.5865 - val_loss: 33543411712.0000\n",
      "Epoch 16/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 39077626957.7721 - val_loss: 33138485248.0000\n",
      "Epoch 17/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 38961771545.9240 - val_loss: 32502288384.0000\n",
      "Epoch 18/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 40795159599.5274 - val_loss: 32451850240.0000\n",
      "Epoch 19/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 34618737314.0253 - val_loss: 32059635712.0000\n",
      "Epoch 20/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 43189028466.4979 - val_loss: 31721371648.0000\n",
      "Epoch 21/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 34106456191.4599 - val_loss: 32076693504.0000\n",
      "Epoch 22/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 36790533698.9705 - val_loss: 31447961600.0000\n",
      "Epoch 23/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33281091000.7089 - val_loss: 31380398080.0000\n",
      "Epoch 24/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31243179859.1730 - val_loss: 32220473344.0000\n",
      "Epoch 25/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31606105234.9030 - val_loss: 31269947392.0000\n",
      "Epoch 26/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32487998006.0084 - val_loss: 31640985600.0000\n",
      "Epoch 27/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32217204982.2785 - val_loss: 30927196160.0000\n",
      "Epoch 28/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31179559840.9451 - val_loss: 30963933184.0000\n",
      "Epoch 29/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 34060568792.0338 - val_loss: 30803423232.0000\n",
      "Epoch 30/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33009698548.1181 - val_loss: 30891552768.0000\n",
      "Epoch 31/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33116099192.9789 - val_loss: 30732449792.0000\n",
      "Epoch 32/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32267606806.6835 - val_loss: 30501605376.0000\n",
      "Epoch 33/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30810921526.0084 - val_loss: 30711707648.0000\n",
      "Epoch 34/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31393452533.1983 - val_loss: 30578890752.0000\n",
      "Epoch 35/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32784519353.7890 - val_loss: 30441666560.0000\n",
      "Epoch 36/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31333228090.3291 - val_loss: 30296655872.0000\n",
      "Epoch 37/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 35747629749.4684 - val_loss: 30239666176.0000\n",
      "Epoch 38/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32795074352.6076 - val_loss: 30263932928.0000\n",
      "Epoch 39/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33273336432.3376 - val_loss: 30166898688.0000\n",
      "Epoch 40/300\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 32736541190.4810 - val_loss: 29926430720.0000\n",
      "Epoch 41/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32265856890.0591 - val_loss: 29885317120.0000\n",
      "Epoch 42/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32428941286.0760 - val_loss: 30193989632.0000\n",
      "Epoch 43/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30584285704.6413 - val_loss: 29847730176.0000\n",
      "Epoch 44/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31371247940.0506 - val_loss: 29754085376.0000\n",
      "Epoch 45/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31942738844.6245 - val_loss: 29874698240.0000\n",
      "Epoch 46/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31989509158.8861 - val_loss: 29976025088.0000\n",
      "Epoch 47/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 34565999195.8143 - val_loss: 29542901760.0000\n",
      "Epoch 48/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33749244340.3882 - val_loss: 29480613888.0000\n",
      "Epoch 49/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32434316495.3924 - val_loss: 29855700992.0000\n",
      "Epoch 50/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32748531206.4810 - val_loss: 29293834240.0000\n",
      "Epoch 51/300\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 32813849634.5654 - val_loss: 29517938688.0000\n",
      "Epoch 52/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32081009713.6878 - val_loss: 29600065536.0000\n",
      "Epoch 53/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30120771933.9747 - val_loss: 29569998848.0000\n",
      "Epoch 54/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32989815773.4346 - val_loss: 29485713408.0000\n",
      "Epoch 55/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28944399697.0127 - val_loss: 29660340224.0000\n",
      "Epoch 56/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30008018879.1899 - val_loss: 29319403520.0000\n",
      "Epoch 57/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28095944466.3629 - val_loss: 29717811200.0000\n",
      "Epoch 58/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32753595420.0844 - val_loss: 29160216576.0000\n",
      "Epoch 59/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31603145460.1181 - val_loss: 29016815616.0000\n",
      "Epoch 60/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31989517327.1224 - val_loss: 29709324288.0000\n",
      "Epoch 61/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32034711465.5865 - val_loss: 28782098432.0000\n",
      "Epoch 62/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30524481758.5148 - val_loss: 29481568256.0000\n",
      "Epoch 63/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31533167335.1561 - val_loss: 29053671424.0000\n",
      "Epoch 64/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26496487773.9747 - val_loss: 29363699712.0000\n",
      "Epoch 65/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31287369676.1519 - val_loss: 28923559936.0000\n",
      "Epoch 66/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33419506184.6413 - val_loss: 28772630528.0000\n",
      "Epoch 67/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32513310145.3502 - val_loss: 28677554176.0000\n",
      "Epoch 68/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28761153338.3291 - val_loss: 29352609792.0000\n",
      "Epoch 69/300\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 29826687390.7848 - val_loss: 28939649024.0000\n",
      "Epoch 70/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32228195695.2574 - val_loss: 29094297600.0000\n",
      "Epoch 71/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30386283204.5907 - val_loss: 29065555968.0000\n",
      "Epoch 72/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31479837678.7173 - val_loss: 28907323392.0000\n",
      "Epoch 73/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29398925031.1561 - val_loss: 29313826816.0000\n",
      "Epoch 74/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28008881992.3713 - val_loss: 29224142848.0000\n",
      "Epoch 75/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29591847274.9367 - val_loss: 28599750656.0000\n",
      "Epoch 76/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30088463061.8734 - val_loss: 28869558272.0000\n",
      "Epoch 77/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27949019926.6835 - val_loss: 29063147520.0000\n",
      "Epoch 78/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28590299081.9916 - val_loss: 28787847168.0000\n",
      "Epoch 79/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29860313219.7806 - val_loss: 28807979008.0000\n",
      "Epoch 80/300\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 31206187980.1519 - val_loss: 28503318528.0000\n",
      "Epoch 81/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30676017156.3207 - val_loss: 28507439104.0000\n",
      "Epoch 82/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29716400918.6835 - val_loss: 28222468096.0000\n",
      "Epoch 83/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29526446732.4219 - val_loss: 28385574912.0000\n",
      "Epoch 84/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28997365392.7426 - val_loss: 28527233024.0000\n",
      "Epoch 85/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28193622975.1899 - val_loss: 29075642368.0000\n",
      "Epoch 86/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29851326299.8143 - val_loss: 28407879680.0000\n",
      "Epoch 87/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28912912414.2447 - val_loss: 28572975104.0000\n",
      "Epoch 88/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30184496773.9409 - val_loss: 28461307904.0000\n",
      "Epoch 89/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29958400626.4979 - val_loss: 27887654912.0000\n",
      "Epoch 90/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28797964318.2447 - val_loss: 28641441792.0000\n",
      "Epoch 91/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32161997659.8143 - val_loss: 28195581952.0000\n",
      "Epoch 92/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28373087443.7131 - val_loss: 28692666368.0000\n",
      "Epoch 93/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30053382100.7932 - val_loss: 28425433088.0000\n",
      "Epoch 94/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31587944724.5232 - val_loss: 28481054720.0000\n",
      "Epoch 95/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32440546018.8354 - val_loss: 28160401408.0000\n",
      "Epoch 96/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28266185684.7932 - val_loss: 28255209472.0000\n",
      "Epoch 97/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29676065321.0464 - val_loss: 28536268800.0000\n",
      "Epoch 98/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28713307451.4093 - val_loss: 28173275136.0000\n",
      "Epoch 99/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27999988723.0380 - val_loss: 27853678592.0000\n",
      "Epoch 100/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33465254648.4388 - val_loss: 28237488128.0000\n",
      "Epoch 101/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29868684387.3755 - val_loss: 28195301376.0000\n",
      "Epoch 102/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29074687408.0675 - val_loss: 28020221952.0000\n",
      "Epoch 103/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31016815583.5949 - val_loss: 28039096320.0000\n",
      "Epoch 104/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26750557957.4008 - val_loss: 27661819904.0000\n",
      "Epoch 105/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28601080844.9620 - val_loss: 28224024576.0000\n",
      "Epoch 106/300\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 29631299795.7131 - val_loss: 27794511872.0000\n",
      "Epoch 107/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28956323801.1139 - val_loss: 27578193920.0000\n",
      "Epoch 108/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29319011410.0928 - val_loss: 27533201408.0000\n",
      "Epoch 109/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33342952128.2700 - val_loss: 27244658688.0000\n",
      "Epoch 110/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30866679077.8059 - val_loss: 27272359936.0000\n",
      "Epoch 111/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29687566867.4430 - val_loss: 27937083392.0000\n",
      "Epoch 112/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27236484558.3122 - val_loss: 27930990592.0000\n",
      "Epoch 113/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29315739293.7046 - val_loss: 27777064960.0000\n",
      "Epoch 114/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27123808176.0675 - val_loss: 27538477056.0000\n",
      "Epoch 115/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27220503115.6118 - val_loss: 27673327616.0000\n",
      "Epoch 116/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28644326127.7975 - val_loss: 27918786560.0000\n",
      "Epoch 117/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29997668516.1857 - val_loss: 27523663872.0000\n",
      "Epoch 118/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27935371983.3924 - val_loss: 27648397312.0000\n",
      "Epoch 119/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27170719944.9114 - val_loss: 28003766272.0000\n",
      "Epoch 120/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31637539431.6962 - val_loss: 27282534400.0000\n",
      "Epoch 121/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28033778994.7679 - val_loss: 27687694336.0000\n",
      "Epoch 122/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28092962906.7342 - val_loss: 28020221952.0000\n",
      "Epoch 123/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26849746926.7173 - val_loss: 27507060736.0000\n",
      "Epoch 124/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25914487669.7384 - val_loss: 28041433088.0000\n",
      "Epoch 125/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27788259602.3629 - val_loss: 27663278080.0000\n",
      "Epoch 126/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29829107997.1646 - val_loss: 27451721728.0000\n",
      "Epoch 127/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27708295530.9367 - val_loss: 27319881728.0000\n",
      "Epoch 128/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27488096746.3966 - val_loss: 27502710784.0000\n",
      "Epoch 129/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26066409476.3207 - val_loss: 27544086528.0000\n",
      "Epoch 130/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25681724044.4219 - val_loss: 27484776448.0000\n",
      "Epoch 131/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29159672840.6413 - val_loss: 26912276480.0000\n",
      "Epoch 132/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27798001689.9240 - val_loss: 27047378944.0000\n",
      "Epoch 133/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28234801674.8017 - val_loss: 27052232704.0000\n",
      "Epoch 134/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28369611659.3418 - val_loss: 27101636608.0000\n",
      "Epoch 135/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31460969541.1308 - val_loss: 26808555520.0000\n",
      "Epoch 136/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26178199694.5823 - val_loss: 28047874048.0000\n",
      "Epoch 137/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26302509086.2447 - val_loss: 26780010496.0000\n",
      "Epoch 138/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28397789404.3544 - val_loss: 27501121536.0000\n",
      "Epoch 139/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27048655992.9789 - val_loss: 27839844352.0000\n",
      "Epoch 140/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27009483266.1603 - val_loss: 26935119872.0000\n",
      "Epoch 141/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27051111367.8312 - val_loss: 27102472192.0000\n",
      "Epoch 142/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26312575943.8312 - val_loss: 26921560064.0000\n",
      "Epoch 143/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28662091106.2954 - val_loss: 27275454464.0000\n",
      "Epoch 144/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28541951166.1097 - val_loss: 26923333632.0000\n",
      "Epoch 145/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28441584419.6456 - val_loss: 26530547712.0000\n",
      "Epoch 146/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25439246914.9705 - val_loss: 26941233152.0000\n",
      "Epoch 147/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26301252754.9030 - val_loss: 26873575424.0000\n",
      "Epoch 148/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25877693092.1857 - val_loss: 26806708224.0000\n",
      "Epoch 149/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28673323176.5063 - val_loss: 26539485184.0000\n",
      "Epoch 150/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26730331693.3671 - val_loss: 26626205696.0000\n",
      "Epoch 151/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26150544867.9156 - val_loss: 27193491456.0000\n",
      "Epoch 152/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24420868881.2827 - val_loss: 27315853312.0000\n",
      "Epoch 153/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26789857988.5907 - val_loss: 26834079744.0000\n",
      "Epoch 154/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29392411678.2447 - val_loss: 26231724032.0000\n",
      "Epoch 155/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24766218259.4430 - val_loss: 27277918208.0000\n",
      "Epoch 156/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26399111669.1983 - val_loss: 26775169024.0000\n",
      "Epoch 157/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26320025280.2700 - val_loss: 26988292096.0000\n",
      "Epoch 158/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29927718924.9620 - val_loss: 26598027264.0000\n",
      "Epoch 159/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28908675616.4051 - val_loss: 26816059392.0000\n",
      "Epoch 160/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24979998927.3924 - val_loss: 26356895744.0000\n",
      "Epoch 161/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30276607766.6835 - val_loss: 26311716864.0000\n",
      "Epoch 162/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26529527816.6413 - val_loss: 26843873280.0000\n",
      "Epoch 163/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26043751315.9831 - val_loss: 26685603840.0000\n",
      "Epoch 164/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26130449070.9873 - val_loss: 26763382784.0000\n",
      "Epoch 165/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27655275610.7342 - val_loss: 26435401728.0000\n",
      "Epoch 166/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26098496589.7722 - val_loss: 26617042944.0000\n",
      "Epoch 167/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26015094040.8439 - val_loss: 26520737792.0000\n",
      "Epoch 168/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30284415485.8397 - val_loss: 26083440640.0000\n",
      "Epoch 169/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24804920162.2954 - val_loss: 26669058048.0000\n",
      "Epoch 170/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26400640996.9958 - val_loss: 26692059136.0000\n",
      "Epoch 171/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26077698529.7553 - val_loss: 26600366080.0000\n",
      "Epoch 172/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25928557196.4219 - val_loss: 26715936768.0000\n",
      "Epoch 173/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25697941907.9831 - val_loss: 26896896000.0000\n",
      "Epoch 174/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26895053737.5865 - val_loss: 26364409856.0000\n",
      "Epoch 175/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24131411449.5190 - val_loss: 26350006272.0000\n",
      "Epoch 176/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24857721238.1435 - val_loss: 26322538496.0000\n",
      "Epoch 177/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26279894832.6076 - val_loss: 26367954944.0000\n",
      "Epoch 178/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25688527524.1857 - val_loss: 26687129600.0000\n",
      "Epoch 179/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26679519313.0127 - val_loss: 26156025856.0000\n",
      "Epoch 180/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26249276891.2743 - val_loss: 26445512704.0000\n",
      "Epoch 181/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25598163736.8439 - val_loss: 26276069376.0000\n",
      "Epoch 182/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24775951061.8734 - val_loss: 26245482496.0000\n",
      "Epoch 183/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25127147392.5401 - val_loss: 25901467648.0000\n",
      "Epoch 184/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25851986905.1139 - val_loss: 25907996672.0000\n",
      "Epoch 185/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27476868878.0422 - val_loss: 26100228096.0000\n",
      "Epoch 186/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27809839276.8270 - val_loss: 25899530240.0000\n",
      "Epoch 187/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29631705973.7384 - val_loss: 26415906816.0000\n",
      "Epoch 188/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26481420491.0717 - val_loss: 25795094528.0000\n",
      "Epoch 189/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25555718904.4388 - val_loss: 25871716352.0000\n",
      "Epoch 190/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27947090823.0211 - val_loss: 26442033152.0000\n",
      "Epoch 191/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26155448648.3713 - val_loss: 25958053888.0000\n",
      "Epoch 192/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24984197953.8903 - val_loss: 25878935552.0000\n",
      "Epoch 193/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26026877744.6076 - val_loss: 26389276672.0000\n",
      "Epoch 194/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26158006567.9662 - val_loss: 27071913984.0000\n",
      "Epoch 195/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25939420665.5190 - val_loss: 25701421056.0000\n",
      "Epoch 196/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25660345363.4430 - val_loss: 26173024256.0000\n",
      "Epoch 197/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24337140848.3376 - val_loss: 26002368512.0000\n",
      "Epoch 198/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25057883170.5654 - val_loss: 25904021504.0000\n",
      "Epoch 199/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26369659986.0928 - val_loss: 25868906496.0000\n",
      "Epoch 200/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26902728557.0970 - val_loss: 25833988096.0000\n",
      "Epoch 201/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25953690530.0253 - val_loss: 25617938432.0000\n",
      "Epoch 202/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25404496444.4895 - val_loss: 25954822144.0000\n",
      "Epoch 203/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26543737307.2743 - val_loss: 26196830208.0000\n",
      "Epoch 204/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24645359315.7131 - val_loss: 26049099776.0000\n",
      "Epoch 205/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25084373108.6582 - val_loss: 26523238400.0000\n",
      "Epoch 206/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25899338829.7722 - val_loss: 25882443776.0000\n",
      "Epoch 207/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25228971124.6582 - val_loss: 25995896832.0000\n",
      "Epoch 208/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24941200764.2194 - val_loss: 25760757760.0000\n",
      "Epoch 209/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25672653448.1013 - val_loss: 25739634688.0000\n",
      "Epoch 210/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25891136172.8270 - val_loss: 26033324032.0000\n",
      "Epoch 211/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25380572164.3207 - val_loss: 25832790016.0000\n",
      "Epoch 212/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26229883281.8228 - val_loss: 25732425728.0000\n",
      "Epoch 213/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25248739029.8734 - val_loss: 26277818368.0000\n",
      "Epoch 214/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25756368692.9283 - val_loss: 26025844736.0000\n",
      "Epoch 215/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24510527578.7342 - val_loss: 25948932096.0000\n",
      "Epoch 216/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25280257570.5654 - val_loss: 25451382784.0000\n",
      "Epoch 217/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25365944229.2658 - val_loss: 25398511616.0000\n",
      "Epoch 218/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23345665032.6413 - val_loss: 26094393344.0000\n",
      "Epoch 219/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25497607098.8692 - val_loss: 25894707200.0000\n",
      "Epoch 220/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25145684335.2574 - val_loss: 25927819264.0000\n",
      "Epoch 221/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25548320169.5865 - val_loss: 25402662912.0000\n",
      "Epoch 222/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27627446621.9747 - val_loss: 25765982208.0000\n",
      "Epoch 223/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25231576079.1224 - val_loss: 25564604416.0000\n",
      "Epoch 224/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25261987086.0422 - val_loss: 25116770304.0000\n",
      "Epoch 225/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25873251289.1139 - val_loss: 25461800960.0000\n",
      "Epoch 226/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24649840255.4599 - val_loss: 25616855040.0000\n",
      "Epoch 227/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25444714629.9409 - val_loss: 25420445696.0000\n",
      "Epoch 228/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24731760964.0506 - val_loss: 25979244544.0000\n",
      "Epoch 229/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24952317869.9072 - val_loss: 25215051776.0000\n",
      "Epoch 230/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25946474513.2827 - val_loss: 25473710080.0000\n",
      "Epoch 231/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24292051643.9494 - val_loss: 25567692800.0000\n",
      "Epoch 232/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24672827348.7932 - val_loss: 25772748800.0000\n",
      "Epoch 233/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27455849765.8059 - val_loss: 25498660864.0000\n",
      "Epoch 234/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26039525069.2321 - val_loss: 25463824384.0000\n",
      "Epoch 235/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24638672332.1519 - val_loss: 25461383168.0000\n",
      "Epoch 236/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24729375128.3038 - val_loss: 25054994432.0000\n",
      "Epoch 237/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24506136653.7722 - val_loss: 25761837056.0000\n",
      "Epoch 238/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24528627923.7131 - val_loss: 25309894656.0000\n",
      "Epoch 239/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26675145118.7848 - val_loss: 25213546496.0000\n",
      "Epoch 240/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23230949870.7173 - val_loss: 25769531392.0000\n",
      "Epoch 241/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25862521510.3460 - val_loss: 25074446336.0000\n",
      "Epoch 242/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25308743122.6329 - val_loss: 25152288768.0000\n",
      "Epoch 243/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26569811713.0802 - val_loss: 25326458880.0000\n",
      "Epoch 244/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24650388886.1435 - val_loss: 25569662976.0000\n",
      "Epoch 245/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24450437919.3249 - val_loss: 25644613632.0000\n",
      "Epoch 246/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23738246770.4979 - val_loss: 25490663424.0000\n",
      "Epoch 247/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25044955941.8059 - val_loss: 25300080640.0000\n",
      "Epoch 248/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24579827171.9156 - val_loss: 25851920384.0000\n",
      "Epoch 249/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23695801719.8987 - val_loss: 25988114432.0000\n",
      "Epoch 250/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24790062542.3122 - val_loss: 25642893312.0000\n",
      "Epoch 251/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25635145231.1224 - val_loss: 24919404544.0000\n",
      "Epoch 252/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25852714377.1814 - val_loss: 24954134528.0000\n",
      "Epoch 253/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25216659818.9367 - val_loss: 25360435200.0000\n",
      "Epoch 254/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23372847134.2447 - val_loss: 25513412608.0000\n",
      "Epoch 255/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23311816483.6456 - val_loss: 25598390272.0000\n",
      "Epoch 256/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24127176930.8354 - val_loss: 25244717056.0000\n",
      "Epoch 257/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25757180986.3291 - val_loss: 24991856640.0000\n",
      "Epoch 258/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23586128446.6498 - val_loss: 25221167104.0000\n",
      "Epoch 259/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27025838771.3080 - val_loss: 24812189696.0000\n",
      "Epoch 260/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22318389731.9156 - val_loss: 25142132736.0000\n",
      "Epoch 261/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23754587094.9536 - val_loss: 24992540672.0000\n",
      "Epoch 262/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25251983092.1181 - val_loss: 24985772032.0000\n",
      "Epoch 263/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25296403347.9831 - val_loss: 25520033792.0000\n",
      "Epoch 264/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23535355515.1392 - val_loss: 25482246144.0000\n",
      "Epoch 265/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22519352963.7806 - val_loss: 25083656192.0000\n",
      "Epoch 266/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23814699720.9114 - val_loss: 24887808000.0000\n",
      "Epoch 267/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24195909960.3713 - val_loss: 25181022208.0000\n",
      "Epoch 268/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26467853964.4219 - val_loss: 24653725696.0000\n",
      "Epoch 269/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24202703081.3165 - val_loss: 24955486208.0000\n",
      "Epoch 270/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25047280493.0970 - val_loss: 25176422400.0000\n",
      "Epoch 271/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24444215594.1266 - val_loss: 25104588800.0000\n",
      "Epoch 272/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23559560898.4304 - val_loss: 25246046208.0000\n",
      "Epoch 273/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25281495247.3924 - val_loss: 24852875264.0000\n",
      "Epoch 274/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22763270645.1983 - val_loss: 25180381184.0000\n",
      "Epoch 275/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23764231664.8776 - val_loss: 25389537280.0000\n",
      "Epoch 276/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25486285724.6245 - val_loss: 24623091712.0000\n",
      "Epoch 277/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25235430313.5865 - val_loss: 25459015680.0000\n",
      "Epoch 278/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23583358608.7426 - val_loss: 24987650048.0000\n",
      "Epoch 279/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22966712946.4979 - val_loss: 25370630144.0000\n",
      "Epoch 280/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24942607480.9789 - val_loss: 25240604672.0000\n",
      "Epoch 281/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23548871044.8608 - val_loss: 25239865344.0000\n",
      "Epoch 282/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23579802978.2954 - val_loss: 24756905984.0000\n",
      "Epoch 283/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24768158063.2574 - val_loss: 24838412288.0000\n",
      "Epoch 284/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21972188130.8354 - val_loss: 25719576576.0000\n",
      "Epoch 285/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24577596472.1688 - val_loss: 24616290304.0000\n",
      "Epoch 286/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23222761002.1266 - val_loss: 24801814528.0000\n",
      "Epoch 287/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25337017354.8017 - val_loss: 25022027776.0000\n",
      "Epoch 288/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23669283781.6709 - val_loss: 24640296960.0000\n",
      "Epoch 289/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22606165737.3165 - val_loss: 25502615552.0000\n",
      "Epoch 290/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24027383183.6624 - val_loss: 24555540480.0000\n",
      "Epoch 291/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23376682487.3587 - val_loss: 25279332352.0000\n",
      "Epoch 292/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23223204706.2954 - val_loss: 25334212608.0000\n",
      "Epoch 293/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22664458395.5443 - val_loss: 25673127936.0000\n",
      "Epoch 294/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23477368716.4219 - val_loss: 24652138496.0000\n",
      "Epoch 295/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25241671770.7342 - val_loss: 24952229888.0000\n",
      "Epoch 296/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23754689060.7257 - val_loss: 24623933440.0000\n",
      "Epoch 297/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24648117822.6498 - val_loss: 24595005440.0000\n",
      "Epoch 298/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22612351710.5148 - val_loss: 24206112768.0000\n",
      "Epoch 299/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21832396590.4473 - val_loss: 24935186432.0000\n",
      "Epoch 300/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23974501177.2489 - val_loss: 24959113216.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa281e00890>"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training with RMSprop\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(2,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "model.compile(optimizer='RMSprop',loss='mse')\n",
    "\n",
    "model.fit(x=X_train,y=y_train,\n",
    "          validation_data=(X_test,y_test),\n",
    "          batch_size=32,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "dUQyLcT_Gqrj",
    "outputId": "e32645ff-d147-4419-ab63-0ae76086339a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.346859e+11</td>\n",
       "      <td>4.065883e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.299465e+11</td>\n",
       "      <td>3.934659e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.914120e+11</td>\n",
       "      <td>3.211490e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.605492e+11</td>\n",
       "      <td>1.517417e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.094833e+11</td>\n",
       "      <td>7.722177e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2.357364e+10</td>\n",
       "      <td>2.462393e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2.357793e+10</td>\n",
       "      <td>2.459501e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2.354140e+10</td>\n",
       "      <td>2.420611e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2.357386e+10</td>\n",
       "      <td>2.493519e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2.355554e+10</td>\n",
       "      <td>2.495911e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss      val_loss\n",
       "0    4.346859e+11  4.065883e+11\n",
       "1    4.299465e+11  3.934659e+11\n",
       "2    3.914120e+11  3.211490e+11\n",
       "3    2.605492e+11  1.517417e+11\n",
       "4    1.094833e+11  7.722177e+10\n",
       "..            ...           ...\n",
       "295  2.357364e+10  2.462393e+10\n",
       "296  2.357793e+10  2.459501e+10\n",
       "297  2.354140e+10  2.420611e+10\n",
       "298  2.357386e+10  2.493519e+10\n",
       "299  2.355554e+10  2.495911e+10\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl_rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "id": "0YVHMuQRCjAJ",
    "outputId": "1dd64b3e-1ce6-4345-82e5-8cdd58da78a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa281c0e150>"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfl_rms= pd.DataFrame(model.history.history)\n",
    "dfl_rms.plot(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGNPR7r4D5gf",
    "outputId": "1e7a3d44-010f-408e-9b96-55a6b48b1c9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "473/473 [==============================] - 2s 2ms/step - loss: 392197321205.1983 - val_loss: 57441693696.0000\n",
      "Epoch 2/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 56187035552.9451 - val_loss: 42105872384.0000\n",
      "Epoch 3/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 42166481449.0464 - val_loss: 35728105472.0000\n",
      "Epoch 4/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 37753110571.2067 - val_loss: 34108579840.0000\n",
      "Epoch 5/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 38694391388.8945 - val_loss: 31726002176.0000\n",
      "Epoch 6/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 34090338161.4177 - val_loss: 31289636864.0000\n",
      "Epoch 7/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 34128868516.1857 - val_loss: 30829019136.0000\n",
      "Epoch 8/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33784381424.8776 - val_loss: 30449125376.0000\n",
      "Epoch 9/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33510090656.9451 - val_loss: 31228780544.0000\n",
      "Epoch 10/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33356068302.3122 - val_loss: 30052425728.0000\n",
      "Epoch 11/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31962383800.7089 - val_loss: 30079320064.0000\n",
      "Epoch 12/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31865022183.1561 - val_loss: 32051990528.0000\n",
      "Epoch 13/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 33600553521.6878 - val_loss: 29838405632.0000\n",
      "Epoch 14/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31729761262.7173 - val_loss: 29365223424.0000\n",
      "Epoch 15/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31259151601.9578 - val_loss: 29729384448.0000\n",
      "Epoch 16/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29716260509.7046 - val_loss: 29599547392.0000\n",
      "Epoch 17/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 32599209659.9494 - val_loss: 29798905856.0000\n",
      "Epoch 18/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30183465893.2658 - val_loss: 29243955200.0000\n",
      "Epoch 19/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30514904789.8734 - val_loss: 28960532480.0000\n",
      "Epoch 20/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31180471920.3376 - val_loss: 28940099584.0000\n",
      "Epoch 21/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29167569950.2447 - val_loss: 28696786944.0000\n",
      "Epoch 22/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 30687161555.7131 - val_loss: 28751773696.0000\n",
      "Epoch 23/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28833697560.8439 - val_loss: 29103394816.0000\n",
      "Epoch 24/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 31402616732.6245 - val_loss: 29361805312.0000\n",
      "Epoch 25/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 29367123484.0844 - val_loss: 29922531328.0000\n",
      "Epoch 26/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28457771457.3502 - val_loss: 28309944320.0000\n",
      "Epoch 27/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26425904508.2194 - val_loss: 29955047424.0000\n",
      "Epoch 28/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28250762222.7173 - val_loss: 29654691840.0000\n",
      "Epoch 29/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28100423031.8987 - val_loss: 28368463872.0000\n",
      "Epoch 30/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27640255116.4219 - val_loss: 28631582720.0000\n",
      "Epoch 31/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26145228037.4008 - val_loss: 28491319296.0000\n",
      "Epoch 32/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27556982913.6203 - val_loss: 28089030656.0000\n",
      "Epoch 33/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27541834903.2236 - val_loss: 28243499008.0000\n",
      "Epoch 34/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28088163602.3629 - val_loss: 28785358848.0000\n",
      "Epoch 35/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28897805134.8523 - val_loss: 29050728448.0000\n",
      "Epoch 36/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27904585861.9409 - val_loss: 28997328896.0000\n",
      "Epoch 37/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27045364303.9325 - val_loss: 29503860736.0000\n",
      "Epoch 38/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27506111969.7553 - val_loss: 27634694144.0000\n",
      "Epoch 39/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28318559469.6371 - val_loss: 30448764928.0000\n",
      "Epoch 40/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26988329232.2025 - val_loss: 30735833088.0000\n",
      "Epoch 41/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27866724239.6624 - val_loss: 28500717568.0000\n",
      "Epoch 42/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26613902906.3291 - val_loss: 28609200128.0000\n",
      "Epoch 43/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28586530634.5316 - val_loss: 29846198272.0000\n",
      "Epoch 44/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26700342043.0042 - val_loss: 28993239040.0000\n",
      "Epoch 45/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 28415375601.9578 - val_loss: 27734921216.0000\n",
      "Epoch 46/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26285937651.0380 - val_loss: 27877877760.0000\n",
      "Epoch 47/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27316166055.4262 - val_loss: 28346087424.0000\n",
      "Epoch 48/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26707631168.8101 - val_loss: 28378673152.0000\n",
      "Epoch 49/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25525963209.9916 - val_loss: 27930363904.0000\n",
      "Epoch 50/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26171091613.7046 - val_loss: 28231663616.0000\n",
      "Epoch 51/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26420671511.7637 - val_loss: 27689170944.0000\n",
      "Epoch 52/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27373642682.8692 - val_loss: 27287261184.0000\n",
      "Epoch 53/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26834666776.8439 - val_loss: 27205070848.0000\n",
      "Epoch 54/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 27907832149.3333 - val_loss: 28167157760.0000\n",
      "Epoch 55/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26735884411.1392 - val_loss: 28426350592.0000\n",
      "Epoch 56/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26483773897.9916 - val_loss: 28155049984.0000\n",
      "Epoch 57/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26230195009.8903 - val_loss: 29930954752.0000\n",
      "Epoch 58/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26047677409.7553 - val_loss: 28183906304.0000\n",
      "Epoch 59/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26209533398.9536 - val_loss: 26801043456.0000\n",
      "Epoch 60/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26168069202.0928 - val_loss: 27425091584.0000\n",
      "Epoch 61/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25488606696.2363 - val_loss: 27344914432.0000\n",
      "Epoch 62/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26604617282.9705 - val_loss: 28979857408.0000\n",
      "Epoch 63/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24947840980.7932 - val_loss: 29670309888.0000\n",
      "Epoch 64/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26382142524.4895 - val_loss: 28148760576.0000\n",
      "Epoch 65/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25430354805.7384 - val_loss: 26642610176.0000\n",
      "Epoch 66/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25019164166.4810 - val_loss: 27420760064.0000\n",
      "Epoch 67/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24572122479.2574 - val_loss: 29267191808.0000\n",
      "Epoch 68/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26270173896.9114 - val_loss: 26367778816.0000\n",
      "Epoch 69/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24251067849.9916 - val_loss: 28630106112.0000\n",
      "Epoch 70/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26040327569.8228 - val_loss: 26549641216.0000\n",
      "Epoch 71/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25389492595.5781 - val_loss: 27348846592.0000\n",
      "Epoch 72/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25043091090.9030 - val_loss: 26476398592.0000\n",
      "Epoch 73/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 26447749361.9578 - val_loss: 26994386944.0000\n",
      "Epoch 74/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24306229345.2152 - val_loss: 27162206208.0000\n",
      "Epoch 75/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25233669912.8439 - val_loss: 27121129472.0000\n",
      "Epoch 76/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25334656563.8481 - val_loss: 26809735168.0000\n",
      "Epoch 77/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24418331151.1224 - val_loss: 26318422016.0000\n",
      "Epoch 78/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25103737320.2363 - val_loss: 26914426880.0000\n",
      "Epoch 79/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24467370467.9156 - val_loss: 26689443840.0000\n",
      "Epoch 80/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24990685030.6160 - val_loss: 26482972672.0000\n",
      "Epoch 81/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24513833504.4051 - val_loss: 26840944640.0000\n",
      "Epoch 82/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23865715945.3165 - val_loss: 26225453056.0000\n",
      "Epoch 83/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25006345289.4515 - val_loss: 26755016704.0000\n",
      "Epoch 84/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23496183211.7468 - val_loss: 27032551424.0000\n",
      "Epoch 85/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23613732822.9536 - val_loss: 27322554368.0000\n",
      "Epoch 86/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25212122641.2827 - val_loss: 27757991936.0000\n",
      "Epoch 87/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24909317396.5232 - val_loss: 25876469760.0000\n",
      "Epoch 88/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24740063401.5865 - val_loss: 26293020672.0000\n",
      "Epoch 89/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24733451985.5527 - val_loss: 27422097408.0000\n",
      "Epoch 90/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22908640917.0633 - val_loss: 28193273856.0000\n",
      "Epoch 91/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24207180895.0549 - val_loss: 27115235328.0000\n",
      "Epoch 92/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23210232250.8692 - val_loss: 25926109184.0000\n",
      "Epoch 93/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23687529523.8481 - val_loss: 25772277760.0000\n",
      "Epoch 94/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24182739937.7553 - val_loss: 27962206208.0000\n",
      "Epoch 95/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23351394673.4177 - val_loss: 27108669440.0000\n",
      "Epoch 96/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24448796952.8439 - val_loss: 26380294144.0000\n",
      "Epoch 97/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24753775145.0464 - val_loss: 26968739840.0000\n",
      "Epoch 98/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24396168207.1224 - val_loss: 26812192768.0000\n",
      "Epoch 99/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 25481796275.3080 - val_loss: 26330687488.0000\n",
      "Epoch 100/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23766080295.9662 - val_loss: 27421005824.0000\n",
      "Epoch 101/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24217503964.3544 - val_loss: 25741260800.0000\n",
      "Epoch 102/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23713515232.6751 - val_loss: 25418825728.0000\n",
      "Epoch 103/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23440607357.2996 - val_loss: 27808163840.0000\n",
      "Epoch 104/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24433023058.0928 - val_loss: 26102214656.0000\n",
      "Epoch 105/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22908631610.3291 - val_loss: 26165999616.0000\n",
      "Epoch 106/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22405745072.0675 - val_loss: 28082259968.0000\n",
      "Epoch 107/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22630199328.4051 - val_loss: 28022261760.0000\n",
      "Epoch 108/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22108154957.7722 - val_loss: 27791745024.0000\n",
      "Epoch 109/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22678328551.1561 - val_loss: 25131374592.0000\n",
      "Epoch 110/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 24649959955.4430 - val_loss: 26020751360.0000\n",
      "Epoch 111/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23050662490.7342 - val_loss: 25659209728.0000\n",
      "Epoch 112/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23652709525.0633 - val_loss: 26160603136.0000\n",
      "Epoch 113/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23314791285.7384 - val_loss: 26286823424.0000\n",
      "Epoch 114/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23997239153.4177 - val_loss: 26062587904.0000\n",
      "Epoch 115/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22461189240.9789 - val_loss: 25168603136.0000\n",
      "Epoch 116/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22670651426.5654 - val_loss: 26393552896.0000\n",
      "Epoch 117/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22866390201.7890 - val_loss: 25981175808.0000\n",
      "Epoch 118/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22514376505.2489 - val_loss: 27502807040.0000\n",
      "Epoch 119/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22737120065.8903 - val_loss: 26140809216.0000\n",
      "Epoch 120/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23154128028.6245 - val_loss: 27764815872.0000\n",
      "Epoch 121/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22562148226.7004 - val_loss: 26146871296.0000\n",
      "Epoch 122/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23841093126.4810 - val_loss: 25016190976.0000\n",
      "Epoch 123/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22536213391.6624 - val_loss: 24585013248.0000\n",
      "Epoch 124/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21779545206.8186 - val_loss: 26060759040.0000\n",
      "Epoch 125/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23567907852.9620 - val_loss: 25289138176.0000\n",
      "Epoch 126/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23013430176.9451 - val_loss: 24687788032.0000\n",
      "Epoch 127/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21419005671.1561 - val_loss: 26212415488.0000\n",
      "Epoch 128/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23170739519.7300 - val_loss: 24993026048.0000\n",
      "Epoch 129/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22012933055.1899 - val_loss: 26133069824.0000\n",
      "Epoch 130/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22516428607.7300 - val_loss: 25219172352.0000\n",
      "Epoch 131/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22450380190.7848 - val_loss: 27472064512.0000\n",
      "Epoch 132/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23267256676.4557 - val_loss: 26502090752.0000\n",
      "Epoch 133/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22067784922.1941 - val_loss: 26997331968.0000\n",
      "Epoch 134/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22680894710.2785 - val_loss: 25843679232.0000\n",
      "Epoch 135/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23015991926.8186 - val_loss: 25011492864.0000\n",
      "Epoch 136/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20983522737.1477 - val_loss: 25626079232.0000\n",
      "Epoch 137/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21768769363.1730 - val_loss: 24501307392.0000\n",
      "Epoch 138/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21783029872.3376 - val_loss: 24825931776.0000\n",
      "Epoch 139/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22042953702.0760 - val_loss: 24477841408.0000\n",
      "Epoch 140/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22405827234.0253 - val_loss: 24962265088.0000\n",
      "Epoch 141/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23530968694.8186 - val_loss: 24871407616.0000\n",
      "Epoch 142/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21506009554.6329 - val_loss: 26495281152.0000\n",
      "Epoch 143/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23003440434.7679 - val_loss: 25902094336.0000\n",
      "Epoch 144/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21598256328.9114 - val_loss: 25581522944.0000\n",
      "Epoch 145/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21441036383.0549 - val_loss: 26486069248.0000\n",
      "Epoch 146/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22293464124.4895 - val_loss: 24473821184.0000\n",
      "Epoch 147/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22204667392.0000 - val_loss: 26224054272.0000\n",
      "Epoch 148/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22366226896.4726 - val_loss: 24566235136.0000\n",
      "Epoch 149/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21214890390.1435 - val_loss: 26588805120.0000\n",
      "Epoch 150/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22363356535.8987 - val_loss: 26167586816.0000\n",
      "Epoch 151/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21152971827.8481 - val_loss: 27327391744.0000\n",
      "Epoch 152/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21909730884.0506 - val_loss: 24268873728.0000\n",
      "Epoch 153/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21738074701.7722 - val_loss: 26667917312.0000\n",
      "Epoch 154/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22223616535.7637 - val_loss: 24330221568.0000\n",
      "Epoch 155/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21391891451.6793 - val_loss: 24635340800.0000\n",
      "Epoch 156/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21563867490.2954 - val_loss: 24076756992.0000\n",
      "Epoch 157/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22735442403.9156 - val_loss: 24788326400.0000\n",
      "Epoch 158/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21282446586.5992 - val_loss: 25062850560.0000\n",
      "Epoch 159/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20783345867.0717 - val_loss: 24786225152.0000\n",
      "Epoch 160/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21256311025.9578 - val_loss: 25400872960.0000\n",
      "Epoch 161/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20925646055.1561 - val_loss: 24771008512.0000\n",
      "Epoch 162/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21401451040.4051 - val_loss: 26225446912.0000\n",
      "Epoch 163/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23001686028.9620 - val_loss: 26037303296.0000\n",
      "Epoch 164/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21958361316.9958 - val_loss: 24322506752.0000\n",
      "Epoch 165/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 23266285084.0844 - val_loss: 24481406976.0000\n",
      "Epoch 166/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20585664736.6751 - val_loss: 24641290240.0000\n",
      "Epoch 167/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21240217634.5654 - val_loss: 25628962816.0000\n",
      "Epoch 168/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21081311419.9494 - val_loss: 24352542720.0000\n",
      "Epoch 169/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21320804939.6118 - val_loss: 24111097856.0000\n",
      "Epoch 170/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21199475997.1646 - val_loss: 24736010240.0000\n",
      "Epoch 171/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20696493198.5823 - val_loss: 25077948416.0000\n",
      "Epoch 172/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21063147831.0886 - val_loss: 25865027584.0000\n",
      "Epoch 173/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21176688367.7975 - val_loss: 24935389184.0000\n",
      "Epoch 174/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21668781706.2616 - val_loss: 25203752960.0000\n",
      "Epoch 175/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20996913020.2194 - val_loss: 26885083136.0000\n",
      "Epoch 176/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21940715135.4599 - val_loss: 25675679744.0000\n",
      "Epoch 177/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20067780115.4430 - val_loss: 24566304768.0000\n",
      "Epoch 178/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22148405373.2996 - val_loss: 27395280896.0000\n",
      "Epoch 179/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21554991000.3038 - val_loss: 24664733696.0000\n",
      "Epoch 180/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20611403311.5274 - val_loss: 25133705216.0000\n",
      "Epoch 181/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22179286954.6667 - val_loss: 24656257024.0000\n",
      "Epoch 182/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21629301384.1013 - val_loss: 26297526272.0000\n",
      "Epoch 183/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21443763148.1519 - val_loss: 24287467520.0000\n",
      "Epoch 184/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21562566887.1561 - val_loss: 24293240832.0000\n",
      "Epoch 185/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20882965108.6582 - val_loss: 24283373568.0000\n",
      "Epoch 186/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21873775127.7637 - val_loss: 27224969216.0000\n",
      "Epoch 187/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21377884209.6878 - val_loss: 25168701440.0000\n",
      "Epoch 188/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21512663664.3376 - val_loss: 25491847168.0000\n",
      "Epoch 189/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20991087019.7468 - val_loss: 24613806080.0000\n",
      "Epoch 190/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21046562496.2700 - val_loss: 25632827392.0000\n",
      "Epoch 191/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21086925009.5527 - val_loss: 24864059392.0000\n",
      "Epoch 192/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20662395206.2110 - val_loss: 24553435136.0000\n",
      "Epoch 193/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 21675142048.9451 - val_loss: 25042270208.0000\n",
      "Epoch 194/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20390722171.1392 - val_loss: 25765410816.0000\n",
      "Epoch 195/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22014693019.5443 - val_loss: 26195544064.0000\n",
      "Epoch 196/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20686389053.5696 - val_loss: 26300659712.0000\n",
      "Epoch 197/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 22688475935.3249 - val_loss: 24558317568.0000\n",
      "Epoch 198/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20301081853.8397 - val_loss: 23779209216.0000\n",
      "Epoch 199/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20321509704.3713 - val_loss: 24257742848.0000\n",
      "Epoch 200/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 19594602855.6962 - val_loss: 24851546112.0000\n",
      "Epoch 201/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 20152613231.2574 - val_loss: 23183132672.0000\n",
      "Epoch 202/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 19204161324.2869 - val_loss: 22624018432.0000\n",
      "Epoch 203/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 19008427640.9789 - val_loss: 22318225408.0000\n",
      "Epoch 204/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 18648659031.4937 - val_loss: 22668560384.0000\n",
      "Epoch 205/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 19009675341.7722 - val_loss: 22846947328.0000\n",
      "Epoch 206/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 18415199737.5190 - val_loss: 23222034432.0000\n",
      "Epoch 207/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 17783083628.0169 - val_loss: 20922761216.0000\n",
      "Epoch 208/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 18237070466.7004 - val_loss: 23446110208.0000\n",
      "Epoch 209/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 16705780118.1435 - val_loss: 21539874816.0000\n",
      "Epoch 210/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 19027800496.0675 - val_loss: 20243585024.0000\n",
      "Epoch 211/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 17332102154.8017 - val_loss: 21841850368.0000\n",
      "Epoch 212/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 16953082562.4304 - val_loss: 20559529984.0000\n",
      "Epoch 213/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 17158079727.7975 - val_loss: 19907682304.0000\n",
      "Epoch 214/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 16800226036.1181 - val_loss: 21785532416.0000\n",
      "Epoch 215/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 16969805517.2321 - val_loss: 21458051072.0000\n",
      "Epoch 216/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 16433577193.3165 - val_loss: 19897362432.0000\n",
      "Epoch 217/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 17995729325.9072 - val_loss: 21647869952.0000\n",
      "Epoch 218/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 15855756771.9156 - val_loss: 19314122752.0000\n",
      "Epoch 219/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 15750516303.9325 - val_loss: 20315492352.0000\n",
      "Epoch 220/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 17444955023.6624 - val_loss: 20290482176.0000\n",
      "Epoch 221/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 16162470942.2447 - val_loss: 19671394304.0000\n",
      "Epoch 222/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 15755174968.1688 - val_loss: 23184691200.0000\n",
      "Epoch 223/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 16623319729.1477 - val_loss: 19404324864.0000\n",
      "Epoch 224/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 14510187216.4726 - val_loss: 19526131712.0000\n",
      "Epoch 225/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 15462437833.9916 - val_loss: 19068487680.0000\n",
      "Epoch 226/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 16264432571.9494 - val_loss: 19332339712.0000\n",
      "Epoch 227/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 15575370652.6245 - val_loss: 18574340096.0000\n",
      "Epoch 228/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 15032942356.5232 - val_loss: 19336466432.0000\n",
      "Epoch 229/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 15381303628.6920 - val_loss: 18538342400.0000\n",
      "Epoch 230/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 15346004157.0295 - val_loss: 18829363200.0000\n",
      "Epoch 231/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 14614309758.3797 - val_loss: 18536361984.0000\n",
      "Epoch 232/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 14673562984.7764 - val_loss: 18219282432.0000\n",
      "Epoch 233/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 14377540331.4768 - val_loss: 17849884672.0000\n",
      "Epoch 234/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 15083000739.1055 - val_loss: 17885265920.0000\n",
      "Epoch 235/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 15111707717.1308 - val_loss: 17934630912.0000\n",
      "Epoch 236/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 14777726643.3080 - val_loss: 18409039872.0000\n",
      "Epoch 237/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13274677379.7806 - val_loss: 17745244160.0000\n",
      "Epoch 238/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 14788414904.7089 - val_loss: 18165811200.0000\n",
      "Epoch 239/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 14694156257.7553 - val_loss: 17327028224.0000\n",
      "Epoch 240/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 14410881537.0802 - val_loss: 17684697088.0000\n",
      "Epoch 241/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 14244387036.3544 - val_loss: 17984262144.0000\n",
      "Epoch 242/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13959859610.4641 - val_loss: 17495662592.0000\n",
      "Epoch 243/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 14076147526.2110 - val_loss: 17222543360.0000\n",
      "Epoch 244/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 14550215317.0633 - val_loss: 18059526144.0000\n",
      "Epoch 245/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 14506665992.6413 - val_loss: 18084210688.0000\n",
      "Epoch 246/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13552625931.8819 - val_loss: 16873053184.0000\n",
      "Epoch 247/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13584040642.4304 - val_loss: 16569175040.0000\n",
      "Epoch 248/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13562202966.9536 - val_loss: 17286877184.0000\n",
      "Epoch 249/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13845543458.5654 - val_loss: 17204494336.0000\n",
      "Epoch 250/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13446544921.9241 - val_loss: 17113579520.0000\n",
      "Epoch 251/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12350127670.5485 - val_loss: 17131520000.0000\n",
      "Epoch 252/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13605464455.0211 - val_loss: 16507689984.0000\n",
      "Epoch 253/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13883063045.4008 - val_loss: 18247985152.0000\n",
      "Epoch 254/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12386439738.3291 - val_loss: 17256773632.0000\n",
      "Epoch 255/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13102663234.9705 - val_loss: 16331244544.0000\n",
      "Epoch 256/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13531565485.9072 - val_loss: 16346532864.0000\n",
      "Epoch 257/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12723792847.3924 - val_loss: 17013133312.0000\n",
      "Epoch 258/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12776846005.4684 - val_loss: 17520990208.0000\n",
      "Epoch 259/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13679120185.2489 - val_loss: 15995569152.0000\n",
      "Epoch 260/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13783536819.3080 - val_loss: 16209811456.0000\n",
      "Epoch 261/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13418115216.7426 - val_loss: 16057242624.0000\n",
      "Epoch 262/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12828516465.4177 - val_loss: 16824836096.0000\n",
      "Epoch 263/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13085207694.5823 - val_loss: 16415574016.0000\n",
      "Epoch 264/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12494950826.6667 - val_loss: 16888113152.0000\n",
      "Epoch 265/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13229133039.7975 - val_loss: 16719692800.0000\n",
      "Epoch 266/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12362199041.0802 - val_loss: 15655790592.0000\n",
      "Epoch 267/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12931804391.1561 - val_loss: 16428704768.0000\n",
      "Epoch 268/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12052405884.2194 - val_loss: 16466533376.0000\n",
      "Epoch 269/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13120146060.9620 - val_loss: 15636890624.0000\n",
      "Epoch 270/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 11876023745.8903 - val_loss: 15659738112.0000\n",
      "Epoch 271/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12754171180.2869 - val_loss: 17090881536.0000\n",
      "Epoch 272/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 13034981678.4473 - val_loss: 16431162368.0000\n",
      "Epoch 273/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12246208131.7806 - val_loss: 15738846208.0000\n",
      "Epoch 274/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12647015655.1561 - val_loss: 15193310208.0000\n",
      "Epoch 275/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12445034616.9789 - val_loss: 16080029696.0000\n",
      "Epoch 276/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12359203448.9789 - val_loss: 15829044224.0000\n",
      "Epoch 277/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12091450780.6245 - val_loss: 16654229504.0000\n",
      "Epoch 278/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12648873102.5823 - val_loss: 15293597696.0000\n",
      "Epoch 279/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 11503763721.7215 - val_loss: 15622142976.0000\n",
      "Epoch 280/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12176228591.7975 - val_loss: 15285753856.0000\n",
      "Epoch 281/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 11979506949.4008 - val_loss: 16082954240.0000\n",
      "Epoch 282/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12040309360.3376 - val_loss: 15593622528.0000\n",
      "Epoch 283/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 11690412293.4008 - val_loss: 15905120256.0000\n",
      "Epoch 284/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12274629366.2785 - val_loss: 15815913472.0000\n",
      "Epoch 285/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 11847048045.0970 - val_loss: 15353682944.0000\n",
      "Epoch 286/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 11826506220.5570 - val_loss: 15875952640.0000\n",
      "Epoch 287/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12108943261.7046 - val_loss: 16273172480.0000\n",
      "Epoch 288/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12414776561.9578 - val_loss: 16118759424.0000\n",
      "Epoch 289/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 11516535671.8987 - val_loss: 15255156736.0000\n",
      "Epoch 290/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12402642094.9873 - val_loss: 15263628288.0000\n",
      "Epoch 291/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 11853435067.9494 - val_loss: 16014873600.0000\n",
      "Epoch 292/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 11536683556.7257 - val_loss: 15241409536.0000\n",
      "Epoch 293/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 11381686935.2236 - val_loss: 15363092480.0000\n",
      "Epoch 294/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12199986675.0380 - val_loss: 16239611904.0000\n",
      "Epoch 295/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 11663398152.6413 - val_loss: 15501818880.0000\n",
      "Epoch 296/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 12132172322.5654 - val_loss: 15564513280.0000\n",
      "Epoch 297/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 10928771254.5485 - val_loss: 16024727552.0000\n",
      "Epoch 298/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 11255132546.7004 - val_loss: 15392983040.0000\n",
      "Epoch 299/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 11707912170.3966 - val_loss: 14851906560.0000\n",
      "Epoch 300/300\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 11781446708.9283 - val_loss: 14938849280.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa281b2a450>"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training with different architecture\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "model.compile(optimizer='Adam',loss='mse')\n",
    "\n",
    "\n",
    "model.fit(x=X_train,y=y_train,\n",
    "          validation_data=(X_test,y_test),\n",
    "          batch_size=32,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEL6r5q_EMkD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "House_Price_Prediction_NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
